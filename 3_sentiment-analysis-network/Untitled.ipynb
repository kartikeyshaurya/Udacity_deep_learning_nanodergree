{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentiment Analysis \n",
    "## Reading the Data\n",
    "\n",
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r') # What we know!\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
      "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n"
     ]
    }
   ],
   "source": [
    "#  Develop a predictive theory\n",
    "\n",
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(2137)\n",
    "pretty_print_review_and_label(12816)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT 1 Quick Theory Validation \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import numpy as np\n",
    "# coolections is super easy way to create list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'POSITIVE'):\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(\" \"):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_neg_ratios = Counter()\n",
    "\n",
    "# TODO: Calculate the ratios of positive and negative uses of the most common words\n",
    "#       Consider words to be \"common\" if they've been used at least 100 times\n",
    "for term , cnt in list(total_counts.most_common()):\n",
    "    if (cnt>100):\n",
    "        pos_neg_ratio = positive_counts[term]/ float(negative_counts[term] +1 )\n",
    "        pos_neg_ratios[term]= pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 1.0607993145235326\n",
      "Pos-to-neg ratio for 'amazing' = 4.022813688212928\n",
      "Pos-to-neg ratio for 'terrible' = 0.17744252873563218\n"
     ]
    }
   ],
   "source": [
    "## calculating the most common words in the codes \n",
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we are converting each word to logarithm\n",
    "\n",
    "pos_neg_ratios.most_common()\n",
    "for word,ratio in pos_neg_ratios.most_common():\n",
    "    pos_neg_ratios[word] = np.log(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
      "Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n",
      "Pos-to-neg ratio for 'terrible' = -1.7291085042663878\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_neg_ratios.most_common() \n",
    "# used to seee the most common\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the Text to Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "vocab = set(total_counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74074"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have to create a input of size (1, 74074)\n",
    "layer_0 = np.zeros((1,74074))\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outclassed\n"
     ]
    }
   ],
   "source": [
    "# in layer_0 we have to put the value of possitive thing \n",
    "# creating a dictionary of words in the vocabulary mapped to index position \n",
    "\n",
    "word2index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    if(i == 10):\n",
    "        print(word)\n",
    "    word2index[word] = i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we are implementing of update_input_layer\n",
    "def update_input_layer(review):\n",
    "    global layer_0 \n",
    "    \n",
    "    layer_0 *= 0 \n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "review = \"layer_0 contains one entry for every word in the vocabulary, as shown in the above image. We need to make sure we know the index of each word, so run the following cell to create a lookup table that stores the index of every word.\"\n",
    "revie= []\n",
    "x = 0 \n",
    "for i in review.split(\" \"):\n",
    "    revie.append(i)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_input_layer(reviews[0])\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  getting the target for the label \n",
    "\n",
    "def get_target_for_label(label):\n",
    "    \"\"\"Convert a label to `0` or `1`.\n",
    "    Args:\n",
    "        label(string) - Either \"POSITIVE\" or \"NEGATIVE\".\n",
    "    Returns:\n",
    "        `0` or `1`.\n",
    "    \"\"\"\n",
    "    if (str(label) == \"POSITIVE\"):\n",
    "        label = 1 \n",
    "    else :\n",
    "        label = 0 \n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_target_for_label(labels[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 3 Now the series matter starts \n",
    "## building a complete neural network\n",
    "\n",
    "- creating a basic neural network muck like we have seen earlier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews, labels, hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \"\"\"Create a SentimenNetwork with the given settings\n",
    "        Args:\n",
    "            reviews(list) - List of reviews used for training\n",
    "            labels(list) - List of POSITIVE/NEGATIVE labels associated with the given reviews\n",
    "            hidden_nodes(int) - Number of nodes to create in the hidden layer\n",
    "            learning_rate(float) - Learning rate to use while training\n",
    "        \n",
    "        \"\"\"\n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        review_vocab = set()\n",
    "        # TODO: populate review_vocab with all of the words in the given reviews\n",
    "        #       Remember to split reviews into individual words \n",
    "        #       using \"split(' ')\" instead of \"split()\".\n",
    "        for i in range(len(reviews)):\n",
    "                for word in reviews[i].split(\" \"):\n",
    "                    review_vocab.add(word)\n",
    "                    \n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        label_vocab = set()\n",
    "        # TODO: populate label_vocab with all of the words in the given labels.\n",
    "        #       There is no need to split the labels because each one is a single word.\n",
    "        for i in labels:\n",
    "            label_vocab.add(label)\n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        \n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word]= i\n",
    "        \n",
    "        # TODO: populate self.word2index with indices for all the words in self.review_vocab\n",
    "        #       like you saw earlier in the notebook\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        \n",
    "        for i, label in enumerate(self.label_view):\n",
    "            self.label2index[label] = i\n",
    "        # TODO: do the same thing you did for self.word2index and self.review_vocab, \n",
    "        #       but for self.label2index and self.label_vocab instead\n",
    "         \n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Store the number of nodes in input, hidden, and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "        \n",
    "        # TODO: initialize self.weights_0_1 as a matrix of zeros. These are the weights between\n",
    "        #       the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros(())\n",
    "        \n",
    "        # TODO: initialize self.weights_1_2 as a matrix of random values. \n",
    "        #       These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = None\n",
    "        \n",
    "        # TODO: Create the input layer, a two-dimensional matrix with shape \n",
    "        #       1 x input_nodes, with all values initialized to zero\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        \n",
    "    def update_input_layer(self,review):\n",
    "        # TODO: You can copy most of the code you wrote for update_input_layer \n",
    "        #       earlier in this notebook. \n",
    "        #\n",
    "        #       However, MAKE SURE YOU CHANGE ALL VARIABLES TO REFERENCE\n",
    "        #       THE VERSIONS STORED IN THIS OBJECT, NOT THE GLOBAL OBJECTS.\n",
    "        #       For example, replace \"layer_0 *= 0\" with \"self.layer_0 *= 0\"\n",
    "        pass\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        # TODO: Copy the code you wrote for get_target_for_label \n",
    "        #       earlier in this notebook. \n",
    "        pass\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        # TODO: Return the result of calculating the sigmoid activation function\n",
    "        #       shown in the lectures\n",
    "        pass\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        # TODO: Return the derivative of the sigmoid activation function, \n",
    "        #       where \"output\" is the original output from the sigmoid fucntion \n",
    "        pass\n",
    "\n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "        \n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "\n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # TODO: Get the next review and its correct label\n",
    "            \n",
    "            # TODO: Implement the forward pass through the network. \n",
    "            #       That means use the given review to update the input layer, \n",
    "            #       then calculate values for the hidden layer,\n",
    "            #       and finally calculate the output layer.\n",
    "            # \n",
    "            #       Do not use an activation function for the hidden layer,\n",
    "            #       but use the sigmoid activation function for the output layer.\n",
    "            \n",
    "            # TODO: Implement the back propagation pass here. \n",
    "            #       That means calculate the error for the forward pass's prediction\n",
    "            #       and update the weights in the network according to their\n",
    "            #       contributions toward the error, as calculated via the\n",
    "            #       gradient descent and back propagation algorithms you \n",
    "            #       learned in class.\n",
    "            \n",
    "            # TODO: Keep track of correct predictions. To determine if the prediction was\n",
    "            #       correct, check that the absolute value of the output error \n",
    "            #       is less than 0.5. If so, add one to the correct_so_far count.\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \"\"\"\n",
    "        Attempts to predict the labels for the given testing_reviews,\n",
    "        and uses the test_labels to calculate the accuracy of those predictions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # TODO: Run a forward pass through the network, like you did in the\n",
    "        #       \"train\" function. That means use the given review to \n",
    "        #       update the input layer, then calculate values for the hidden layer,\n",
    "        #       and finally calculate the output layer.\n",
    "        #\n",
    "        #       Note: The review passed into this function for prediction \n",
    "        #             might come from anywhere, so you should convert it \n",
    "        #             to lower case prior to using it.\n",
    "        \n",
    "        # TODO: The output layer should now contain a prediction. \n",
    "        #       Return `POSITIVE` for predictions greater-than-or-equal-to `0.5`, \n",
    "        #       and `NEGATIVE` otherwise.\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
